{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_gbq as pdq\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client(project='analytics-supplychain-thd')\n",
    "import pulp\n",
    "import numpy as np\n",
    "import cplex\n",
    "# import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created results dictionaries\n"
     ]
    }
   ],
   "source": [
    "## Getting regions and initializing dictionaries\n",
    "\n",
    "# regions_query = \"\"\"\n",
    "#                 SELECT DISTINCT REGION\n",
    "#                 FROM `analytics-supplychain-thd.SRS_Matching.DEMAND_DATA`\n",
    "# \"\"\"\n",
    "# regions_data = pdq.read_gbq(regions_query, project_id= 'analytics-supplychain-thd' , dialect='standard')\n",
    "# regions = regions_data['REGION'].tolist()\n",
    "\n",
    "ded_details_dict = {}\n",
    "ow_dict = {}\n",
    "summary_dict = {}\n",
    "print('Created results dictionaries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "0:00:29  data pull from BQ\n",
      "0:00:14  data processing, creating dictionaries\n",
      "0:00:00  model set up\n",
      "0:02:29  constraints set up\n",
      "Version identifier: 22.1.1.0 | 2022-11-27 | 9160aff4d\n",
      "CPXPARAM_Read_DataCheck                          1\n",
      "CPXPARAM_TimeLimit                               1800\n",
      "CPXPARAM_MIP_Tolerances_MIPGap                   0.01\n",
      "Tried aggregator 2 times.\n",
      "MIP Presolve eliminated 14739 rows and 186705 columns.\n",
      "Aggregator did 80 substitutions.\n",
      "Reduced MIP has 3051 rows, 67546 columns, and 131984 nonzeros.\n",
      "Reduced MIP has 34220 binaries, 33326 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.75 sec. (366.15 ticks)\n",
      "Found incumbent of value 2586754.030373 after 1.16 sec. (461.26 ticks)\n",
      "Tried aggregator 1 time.\n",
      "Detecting symmetries...\n",
      "Reduced MIP has 3051 rows, 67546 columns, and 131984 nonzeros.\n",
      "Reduced MIP has 34220 binaries, 33326 generals, 0 SOSs, and 0 indicators.\n",
      "Presolve time = 0.09 sec. (87.00 ticks)\n",
      "Probing time = 0.14 sec. (18.65 ticks)\n",
      "Clique table members: 822.\n",
      "MIP emphasis: balance optimality and feasibility.\n",
      "MIP search method: dynamic search.\n",
      "Parallel mode: deterministic, using up to 12 threads.\n",
      "Root relaxation solution time = 0.12 sec. (65.83 ticks)\n",
      "\n",
      "        Nodes                                         Cuts/\n",
      "   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap\n",
      "\n",
      "*     0+    0                      2586754.0304 -2567298.7539           199.25%\n",
      "*     0+    0                      2538074.1227 -2567298.7539           201.15%\n",
      "*     0     0      integral     0  2513170.8492  2513170.8492     3410    0.00%\n",
      "Elapsed time = 2.27 sec. (758.27 ticks, tree = 0.00 MB, solutions = 3)\n",
      "\n",
      "Root node processing (before b&c):\n",
      "  Real time             =    2.30 sec. (768.66 ticks)\n",
      "Parallel b&c, 12 threads:\n",
      "  Real time             =    0.00 sec. (0.00 ticks)\n",
      "  Sync time (average)   =    0.00 sec.\n",
      "  Wait time (average)   =    0.00 sec.\n",
      "                          ------------\n",
      "Total (root+branch&cut) =    2.30 sec. (768.66 ticks)\n",
      "Cplex status= 101\n",
      "0:00:09  model solved  Optimal\n",
      "0:00:04  results uploaded\n",
      "INPUT------ Demand Lanes: 3574 , Route Choices: 243212\n",
      "OUTPUT----- Routes Chosen: 1858 , One Way Lanes: 1622\n",
      "Completed, Total time:  0:03:25 , Total cost: 2513171.0\n",
      "---------All Completed for Network \n"
     ]
    }
   ],
   "source": [
    "# for region in regions:\n",
    "description = \"SRS Matching\"\n",
    "\n",
    "start_time = datetime.strptime(datetime.now().strftime(\"%H:%M:%S\"),\"%H:%M:%S\")   \n",
    "\n",
    "############## INPUT QUERIES #########\n",
    "q1 = \"\"\"\n",
    "        SELECT DISTINCT \n",
    "            --THD_SRS,\n",
    "            CAST(PAIR_NUMBER AS STRING) AS pair_number\n",
    "            ,loads\n",
    "            ,OW_COST_PER_LOAD AS OW_CPL\n",
    "        FROM `analytics-supplychain-thd.SRS_Matching.DEMAND_DATA`\n",
    "\"\"\"\n",
    "sqllanes = pdq.read_gbq(q1, project_id= 'analytics-supplychain-thd' , dialect='standard')\n",
    "\n",
    "q2 = \"\"\"\n",
    "        SELECT ROUTE_NBR\n",
    "            ,HOME_DC\n",
    "            ,CAST(CASE WHEN A_LOADED_IND = 1 THEN PAIR_NBR1 ELSE null END AS STRING) AS lane_1\n",
    "            ,CAST(CASE WHEN B_LOADED_IND = 1 THEN PAIR_NBR2 ELSE null END AS STRING) AS lane_2\n",
    "            ,CAST(CASE WHEN C_LOADED_IND = 1 THEN PAIR_NBR3 ELSE null END AS STRING) AS lane_3\n",
    "            ,CAST(CASE WHEN D_LOADED_IND = 1 THEN PAIR_NBR4 ELSE null END AS STRING) AS lane_4\n",
    "            ,TOTAL_DIST AS total_dist\n",
    "            ,RF_COST AS cost\n",
    "            ,mode\n",
    "        FROM `analytics-supplychain-thd.SRS_Matching.rf_routes_final`\n",
    "\"\"\"\n",
    "sqlroutedata = pdq.read_gbq(q2, project_id= 'analytics-supplychain-thd' , dialect='standard')\n",
    "\n",
    "q3 = \"\"\"\n",
    "        SELECT DISTINCT \n",
    "            CAST(PAIR_NUMBER AS STRING) AS pair_number\n",
    "        FROM `analytics-supplychain-thd.SRS_Matching.DEMAND_DATA`\n",
    "        WHERE O_TYPE IN ('BDC', 'FDC', 'FDC/BDC', 'BDC/FDC') AND D_TYPE IN ('STR')\n",
    "\"\"\"\n",
    "sqldcstr = pdq.read_gbq(q3, project_id= 'analytics-supplychain-thd' , dialect='standard')\n",
    "\n",
    "q4 = \"\"\"\n",
    "        SELECT DISTINCT \n",
    "            CAST(PAIR_NUMBER AS STRING) AS pair_number\n",
    "        FROM `analytics-supplychain-thd.SRS_Matching.DEMAND_DATA`\n",
    "        WHERE LEG LIKE 'SRS%'\n",
    "\"\"\"\n",
    "sqlsrs = pdq.read_gbq(q4, \n",
    "                      project_id= 'analytics-supplychain-thd' , \n",
    "                      dialect='standard')\n",
    "\n",
    "\n",
    "a = datetime.strptime(datetime.now().strftime(\"%H:%M:%S\"),\"%H:%M:%S\")\n",
    "print(a - start_time, \" data pull from BQ\")\n",
    "\n",
    "routenbr = {}\n",
    "for ind, row in sqlroutedata.iterrows():\n",
    "    route_nbr = row['ROUTE_NBR']\n",
    "    routenbr[(route_nbr)] = []\n",
    "\n",
    "lanes = {}\n",
    "for ind, row in sqllanes.iterrows():\n",
    "    pair_nbr = row['pair_number']\n",
    "    lanes[(pair_nbr)] = []\n",
    "\n",
    "dc_str_lanes = []\n",
    "for ind,row in sqldcstr.iterrows():\n",
    "    pair_nbr = row['pair_number']\n",
    "    dc_str_lanes.append(pair_nbr)\n",
    "\n",
    "srs_lanes = {}\n",
    "for ind,row in sqlsrs.iterrows():\n",
    "    pair_nbr = row['pair_number']\n",
    "    srs_lanes[(pair_nbr)] = []\n",
    "\n",
    "routecost = {}\n",
    "routepairs = {}\n",
    "routedc = {}\n",
    "routedists = {}\n",
    "for ind,row in sqlroutedata.iterrows():\n",
    "    route_nbr, route_cost, route_dc, route_dist, lane_1, lane_2, lane_3, lane_4 =\\\n",
    "    row['ROUTE_NBR'], row['cost'], row['HOME_DC'], row['total_dist'], row['lane_1'], row['lane_2'], row['lane_3'], row['lane_4']\n",
    "\n",
    "    routecost[(route_nbr)] = route_cost\n",
    "    routepairs[(route_nbr)] = (lane_1, lane_2, lane_3, lane_4)\n",
    "    routedc [(route_nbr)] = route_dc\n",
    "    routedists[(route_nbr)] = route_dist\n",
    "\n",
    "owcost = {}\n",
    "demand = {}\n",
    "for ind,row in sqllanes.iterrows():\n",
    "    pair_nbr, loads, ow_cost = row['pair_number'], row['loads'], row['OW_CPL']\n",
    "    owcost[(pair_nbr)] = ow_cost\n",
    "    demand[(pair_nbr)] = loads\n",
    "\n",
    "b = datetime.strptime(datetime.now().strftime(\"%H:%M:%S\"),\"%H:%M:%S\")\n",
    "print(b - a, \" data processing, creating dictionaries\")\n",
    "\n",
    "########## MODEL DEFN #############\n",
    "prob = pulp.LpProblem(\"SRS Matching\", pulp.LpMinimize)\n",
    "\n",
    "###### DVARS ####\n",
    "ded = pulp.LpVariable.dicts(\"Dedicated\", ((route_nbr) for route_nbr in routenbr.keys()), lowBound=0, cat = pulp.LpInteger)\n",
    "ow = pulp.LpVariable.dicts(\"One_Way\", ((pair_nbr) for pair_nbr in lanes.keys()), lowBound=0, cat=pulp.LpInteger)\n",
    "thd_cover = pulp.LpVariable.dicts(\"THD Cover\", ((pair_nbr) for pair_nbr in srs_lanes.keys()), lowBound=0, cat=pulp.LpInteger)\n",
    "\n",
    "lane_ded = pulp.LpVariable.dicts(\"Lane Ded\", ((lane) for lane in lanes.keys()), cat = pulp.LpBinary)\n",
    "lane_ow = pulp.LpVariable.dicts(\"Lane OW\", ((lane) for lane in lanes.keys()), cat = pulp.LpBinary)\n",
    "\n",
    "a = datetime.strptime(datetime.now().strftime(\"%H:%M:%S\"),\"%H:%M:%S\")\n",
    "print(a - b, \" model set up\")\n",
    "\n",
    "########## OBJ FUNCTION ##########\n",
    "prob += pulp.lpSum([ded[(route_nbr)]*routecost[(route_nbr)] \n",
    "                    for route_nbr in routenbr.keys()]) - \\\n",
    "        pulp.lpSum([thd_cover[(pair_number)]*owcost[(pair_number)] \n",
    "                    for pair_number in srs_lanes.keys()])\n",
    "\n",
    "########### CONSTRAINTS #######\n",
    "###Demand\n",
    "for pair_nbr in demand.keys():\n",
    "    routes_with_lane = {k:v for (k,v) in routepairs.items() if pair_nbr in v}\n",
    "    prob += (ow[pair_nbr] + pulp.lpSum([ded[(rn)] for rn in routes_with_lane.keys()]) == demand[(pair_nbr)]\n",
    "                ,\"Demand Constraint for lane number: {}\".format(pair_nbr))\n",
    "    \n",
    "for lane in lanes.keys():\n",
    "    routes_with_lane = {k:v for (k,v) in routepairs.items() if lane in v}\n",
    "    prob += pulp.lpSum([ded[(rn)] for rn in routes_with_lane.keys()]) <= 100000*lane_ded[(lane)]\n",
    "    prob += ow[(lane)] <= 100000*lane_ow[(lane)]\n",
    "\n",
    "for lane in lanes.keys():\n",
    "    prob += lane_ded[(lane)] + lane_ow[(lane)] >= 1\n",
    "\n",
    "for dc_str_lane in dc_str_lanes:\n",
    "    prob += lane_ow[(dc_str_lane)] == 0\n",
    "\n",
    "for srs_lane in list(srs_lanes.keys()):\n",
    "    routes_with_srs_lane = {k:v for (k,v) in routepairs.items() if srs_lane in v} \n",
    "    prob += thd_cover[(srs_lane)] == pulp.lpSum([ded[(rn)] for rn in routes_with_srs_lane.keys()])\n",
    "\n",
    "b = datetime.strptime(datetime.now().strftime(\"%H:%M:%S\"),\"%H:%M:%S\")\n",
    "print(b - a, \" constraints set up\")\n",
    "\n",
    "######### SOLVING THE MODEL #############\n",
    "solver_cplex = pulp.CPLEX_PY(timeLimit = 1800, gapRel = 0.01)\n",
    "prob.solve(solver_cplex)\n",
    "\n",
    "a = datetime.strptime(datetime.now().strftime(\"%H:%M:%S\"),\"%H:%M:%S\")\n",
    "print(a - b, \" model solved \", pulp.LpStatus[prob.status])\n",
    "\n",
    "solution = pd.DataFrame(columns=[\"var\", \"val\"])\n",
    "for v in prob.variables():\n",
    "    if v.varValue != 0:\n",
    "        new_row = pd.DataFrame({\"var\": [v.name], \"val\": [v.varValue]})\n",
    "        solution = pd.concat([solution, new_row], ignore_index=True)\n",
    "        # solution = solution.append({\"var\": v.name, \"val\": v.varValue}, ignore_index=True)\n",
    "\n",
    "one_way = solution[solution['var'].str.contains(\"One_Way\")]\n",
    "dedicated = solution[solution['var'].str.contains(\"Dedicated\")]\n",
    "\n",
    "one_way.columns = ['pair_number', 'LOADS']\n",
    "dedicated.columns = ['ROUTE_NBR', 'LOADS']\n",
    "\n",
    "one_way['pair_number'] = one_way['pair_number'].str.replace(\"One_Way_\", \"\", case=False)\n",
    "dedicated['ROUTE_NBR'] = dedicated['ROUTE_NBR'].str.replace(\"Dedicated_\", \"\", case=False)\n",
    "\n",
    "dedicated['DESCRIPTION'] = description\n",
    "\n",
    "dedicated = dedicated[['ROUTE_NBR','LOADS','DESCRIPTION']]\n",
    "dedicated = dedicated.astype({ \n",
    "                                'ROUTE_NBR': 'int',\n",
    "                                'LOADS': 'int', \n",
    "                                'DESCRIPTION': 'str'})\n",
    "\n",
    "# dedicated['RUN_DATE'] = datetime.now().date()\n",
    "\n",
    "ded_details = pd.merge(dedicated, sqlroutedata[['ROUTE_NBR', 'HOME_DC', 'cost', 'total_dist', 'mode']] \\\n",
    "                        , on = ['ROUTE_NBR'], how = 'left')\n",
    "ded_details.rename(columns={'cost': 'COST',\n",
    "                            'total_dist': 'DIST'},\n",
    "                    inplace=True)\n",
    "ded_details['Run_Date'] = str(datetime.now().date())\n",
    "ded_details['Run_Time'] = str(datetime.now().time().strftime(\"%H:%M\"))\n",
    "one_way['DESCRIPTION'] = description\n",
    "\n",
    "one_way = one_way[['pair_number','LOADS', 'DESCRIPTION']]\n",
    "one_way = one_way.astype({\n",
    "                             \n",
    "                            'pair_number': 'str',\n",
    "                            'LOADS': 'int',\n",
    "                            'DESCRIPTION': 'str'\n",
    "                        })\n",
    "one_way.rename(columns={'pair_number': 'PAIR_NUMBER'}, inplace=True)\n",
    "\n",
    "ded_cost_df = pd.merge(dedicated, sqlroutedata[['ROUTE_NBR','cost']],\\\n",
    "            how = 'left', left_on='ROUTE_NBR', right_on='ROUTE_NBR')\n",
    "ded_cost = sum(ded_cost_df['LOADS'] * ded_cost_df['cost'])\n",
    "\n",
    "ow_cost_df = pd.merge(one_way, sqllanes,\\\n",
    "            how = 'left', left_on='PAIR_NUMBER', right_on='pair_number')\n",
    "ow_cost = sum(ow_cost_df['LOADS'] * ow_cost_df['OW_CPL'])\n",
    "\n",
    "summary = pd.DataFrame(columns=['region','dedicated_cost','ow_cost','total_cost','description'])\n",
    "summary = pd.concat([summary, \n",
    "                        pd.DataFrame({\n",
    "                        'dedicated_cost': [ded_cost], \n",
    "                        'ow_cost': [ow_cost],\n",
    "                        'total_cost': [pulp.value(prob.objective)], \n",
    "                        'description': [description]})] \n",
    "                        ,ignore_index=True\n",
    "                        )\n",
    "\n",
    "# ow_dict[(region)] = one_way\n",
    "# ded_details_dict[(region)] = ded_details\n",
    "# summary_dict[(region)] = summary\n",
    "\n",
    "end_time = datetime.strptime(datetime.now().strftime(\"%H:%M:%S\"),\"%H:%M:%S\")\n",
    "print(end_time- a, \" results uploaded\")\n",
    "\n",
    "print(\"INPUT------ Demand Lanes:\",len(demand),\", Route Choices:\",len(routenbr))\n",
    "print(\"OUTPUT----- Routes Chosen:\",dedicated.shape[0],\", One Way Lanes:\",one_way.shape[0])\n",
    "print(\"Completed, Total time: \", end_time - start_time, \", Total cost:\",\\\n",
    "        round(pulp.value(prob.objective),0))\n",
    "\n",
    "print(\"---------All Completed for Network \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# final_ded_details = pd.concat(ded_details_dict.values(), ignore_index=True)\n",
    "ded_details.to_gbq('SRS_Matching.SRS_MATCHING_DED',\n",
    "               'analytics-supplychain-thd',\n",
    "               chunksize=None,\n",
    "               if_exists='replace'\n",
    "               )\n",
    "# ow_df = pd.concat(ow_dict.values(), ignore_index=True)\n",
    "one_way.to_gbq('SRS_Matching.SRS_MATCHING_OW',\n",
    "               'analytics-supplychain-thd',\n",
    "               chunksize=None,\n",
    "               if_exists='replace'\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cplex310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
